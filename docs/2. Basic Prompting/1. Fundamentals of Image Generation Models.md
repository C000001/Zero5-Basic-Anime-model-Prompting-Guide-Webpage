---
share: true
---

<details open><summary>
<b> Notice:
</b></summary>
 If you are just looking to get started and get going, check out <a href"">Prompting for Dummies</a>. 

 Also, check out <a href="INSERTLINKHERE">Setup</a>. Even people who already got into prompting should make sure that we share similar settings.
 </details>

For our prompting techniques to make sense, we need to understand these key things:
- [[#^e50d25|#How does a model work?]] 
- [[#^488368|What are Tokens]]
- [[#^ea4234|What is a prompt?]]
- [[#^4aac5e|Addendum]]



<details open><summary>
<b><h2> How does a model work?</h2>
</b></summary> 
The model has been trained on a Dataset. A Dataset consists of prompts and pictures. When you then query the model with words, it will try to replicate whatever pattern it found in the pictures with that particular prompt. If the prompt contains words that are not in the Dataset, then it will simply ignore the words, as it doesn't have any pictures or patterns associated with it. 
<br>
To make it visual: The model once visited a museum. The museum is full of all the pictures that we selected for the model. It traces every picture, and now has found a pattern for each word in the museum. These patterns are stored inside the model, and it is what we use when prompting. 
<a href="https://youtu.be/24yjRbBah3w?t=69">Visualization inspired by</a>
 <br>
However, <u><b><font size = 4 color = F1ACAB>Not all words are equal.</font></b></u> Some words are more specific, others the model has barely seen, and some words will fight each other. Making the model apply the desired pattern is the key challenge in prompt engineering. 
<br> 
<details open><summary>
<b> For more resources:
</b></summary>
 Layman: <a href="https://www.youtube.com/watch?v=R9OHn5ZF4Uo">CPGrey</a>
<br>
Math: <a href="https://www.youtube.com/watch?v=aircAruvnKk&list=PL_h2yd2CGtBHEKwEH5iqTZH85wLS-eUzv">3blue1brown</a> (check the description for even more links) (has a lot of translations, check the subtitles!)
</details>
</details>


> [!faq]+ ## What are tokens?
>A prompt gets broken up into tokens. Tokens are model words, words in the language of the model. <br>
>As an example, applepie gets broken up into tokens, which could be <font color=EDED96>apple, applepie, and pie</font>, but might also be <font color=EDED96>apple, applepie</font>. 

^488368

> [!faq]+ ## What is a prompt?
> 
A prompt describes all text you prompt the model with. Some people use prompt interchangeably with token, or mean the word(s) inside the commas. In this guide, I will exclusively use it to refer to **the full text input**.  

^ea4234



> [!info] ## Addendum 
> It is important to be aware of the Stable Diffusion base model you are using. Stable Diffusion 2.1 are prompted differently from Stable Diffusion 1.5 models. Most anime models are based on [[Stable Diffusion 1.5|Stable Diffusion 1.5]] and [[Novel AI or NAI|Novel AI]]. You should be able to check the version here:
> 
> ![](https://lh4.googleusercontent.com/gFysITnyxkBIVRI1_6kBrpA3o366aMmfSSxHDBqcohYkfIBQIviy780R-logt7_yuq3XzKArmTNZLzOYouz_a_XDcHE2y9MYiSHSI3j34fx5Xs7GlGhuvP8RVuudsyw44xIPG8sObHwM_e0p-K8kBGY)

^4aac5e

Next: [[1.1 Samplers]] 