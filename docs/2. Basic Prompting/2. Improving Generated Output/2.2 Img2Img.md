```
---  
share: true  
---  
```

Img2Img is great if you have a source image and want to generate something similar. How similar it is is something you control. 
>[!warning] Note: 
>If you want the specific pose or composition, use ControlNet. 
>If you are using an Upscaler, I recommend this extension: https://github.com/pkuliyi2015/multidiffusion-upscaler-for-automatic1111
>If you want to change one region, e.g. to fix hands, refer to the next section, [[2.3 Inpainting]].

Prompting an image to image picture is slightly different. It depends with the denoising strength, which is the most crucial parameter for img2img. 

The way img2img works is that it adds a bit of noise on top of the image, then removes the noise again. If the denoising is high, as in higher than 0.5, a lot of change will happen. If the denoising is low, not much will change. 

1 will cover the whole picture in noise, 0 will cover it in no noise. 0.3 is recommended for slight changes, 0.6 for bigger changes. You will need to play around with the denoising parameter for each individual picture. 

As for the sampler, use DPM++ 2M Karras.

Let us look at a concrete example. 

I generated this picture of a lovely cat. 

![[00123-1105595110.png]]
But I want the cat to rest in the afternoon sun. 

So I throw it in Img2img, and just prompt as I usually would, without changing a thing.

![[image.png]]

The denoising is set to 0.75, and the sampling method is Euler A. 

I then used it again with DPM++ 2M Karras. 
![[imag1e.png]]
Even though it looks like a worse picture, it actually stuck more closely to the prompt. There is only one cat, and the eyes are now proper slits. 

Okay, I think that too many things are changing. The cat doesn't even have that cute blue ribbon anymore!

So let's set denoising to a 0.5 first. You can see it circled red in the picture (I also highlighted the sampler selection from last step). 
![[2image.png]]
As you can see, it has the blue ribbon now. But honestly? Not much changed. Oh, yes, the left eye no longer looks that awkward, and the colour of the ribbon changed and some of the marks on the fur shifted around, but there is no grass. 

So let us shift denoising strength a little bit higher, to 0.6.
![[4image.png]]

The grass is here. But the blue tie/ribbon is gone. At this point, I think I will just add it to the prompt, and then set denoising a teensy tiny bit higher. It's already doing what it should, I just want a bit more of the outside (which I should also add to the prompt).

![[00006-3292840895.png]]

This kitten looks very marture all of sudden. I feel like the previous cute kitten is gone, even if more of the prompt is fulfilled. So, what do we do here?

We have to set denoising lower, and hope we luck into a good seed that can bring us closer to outside. We can also increase the strength of grass and outside. 
![[5image.png]]
Welp, that didn't go well. Even though the cat remains the same, we just can't get the outside. Why is that so?

The answer lies in how the model does things. Typically, when generating a picture, the model works with random noise at the start, and work its way through each step by removing a bit of the noise. 
The noise has all sorts of colours, so that, even if the starting image does have quite a bit more red or blue, you can still remove red and blue, and have the green from the rest slowly spread through the picture. 
This is not possible if there is no green at all, which is our starting picture.
A way to fix this would be to just literally give the model more green to work with. 
Shoddy paint net work:
![[1-00123-1105595110.png]]

Result:
![[10image.png]]
As you can see, it quickly it! You can even see the white stripe on the right, which previously made sense as the light source, but now makes no sense but has been left alone by the model. Why? Because the denoising is too low, and it didn't really know what to do with that space to begin with, so it just kept the white at each step. 

Okay, that solves the issue of when our prompt is not listened to. You can think of this as some advanced text prompting, where you also feed it a picture of your choosing at the start. The more you know about how the model handles pictures, the better you can handle this kind of prompting. A non-sensical picture says nothing to the model after all.

But what if you are fine with the picture composition and everything in itself? All you want to do is fix these hands, darnit!

Head no further than the next section, [[2.3 Inpainting|Inpainting]], our savior and salvation.
