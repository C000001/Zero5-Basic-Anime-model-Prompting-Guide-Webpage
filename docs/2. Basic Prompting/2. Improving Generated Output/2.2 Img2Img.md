```
---  
share: true  
---  
```

TODO: Go through it via one example. 

Img2Img is great if you have a source image and want something similar. If you want the specific pose or composition, use ControlNet. If you are using an Upscaler, I recommend this extension: https://github.com/pkuliyi2015/multidiffusion-upscaler-for-automatic1111
Otherwise for img2img if you use Latent Upscaler, set Denoise to 0.6.

>[!warning] 
>If you want to change one regional, e.g. fix hands, refer to [[2.3 Inpainting]]

Prompting is slightly different. It is best if you keep your prompts to an absolute minimum. You want to roughly prompt the picture you are going for. Include all the necessary details. 

The way img2img works is that it adds a bit of noise on top of the image, then removes the noise again. If you prompt too much, it will try to change too much. If you prompt too little, the output will be changed from the input. You can adjust the amount of noise through denoising. 1 is a completely different picture, 0 is no noise. 0.3 is recommended for slight changes, 0.6 for bigger changes. You will need to play around with the denoising parameter. 

As for the sampler, use DPM++ 2M Karras.

