---
share: true
---

>[!notice]+ <b> Notice:</b>
>If you are just looking to get started and get going, check out [[Prompting for Dummies]]. 

<p>Also, check out <a href="INSERTLINKHERE">Setup</a>. Even people who already got into prompting should make sure that we share similar settings.</p>
 
## <b>How does a model work?</b>
<p>The model has been trained on a Dataset. A model consists of weights that have information about patterns. A Dataset consists of prompts and pictures. </p><p>
When you then query the model with words, it will try to generate the pictures based on the training data. If the prompt contains words that are not in the training data, then it will simply ignore the words, as it doesn't have any pictures or patterns associated with it. 
</p><p>
More importantly, the model's view is limited, as its world is limited by the training data. It re-creates patterns that it found in the training data. And much like how humans are quick to assume, the model similarly is often inaccurate, or lacking.</p>
<p>Unlike humans, we have immediate ways to combat bias in models. We try to get our desired result anyway. And prompt engineering is a huge part in fighting against bias in a singular model. </p>

>[!info]+ <b> For more resources:</b>
>Layman: <a href="https://www.youtube.com/watch?v=R9OHn5ZF4Uo">CPGrey</a>
>Math: <a href="https://www.youtube.com/watch?v=aircAruvnKk&list=PL_h2yd2CGtBHEKwEH5iqTZH85wLS-eUzv">3Blue1Brown</a> (check the description for even more links) (has a lot of translations, check the subtitles!)
>Programming: <a href="https://www.youtube.com/watch?v=-lz30by8-sU">Codephile</a>
>

## What are tokens?
<p>A prompt gets broken up into tokens. Tokens are model words, words in the language of the model.</p> 
<p>As an example, applepie gets broken up into tokens, which could be <font color=EDED96>apple, applepie, and pie</font>, but might also be <font color=EDED96>apple, applepie</font>. </p>

## What is a prompt?
 <p>A prompt describes all text you prompt the model with. Some people use prompt interchangeably with token, or mean the word(s) inside the commas. In this guide, I will exclusively use it to refer to **the full text input**.  </p>


## Addendum 
<p>It is important to be aware of the Stable Diffusion base model you are using. Stable Diffusion 2.1 are prompted differently from Stable Diffusion 1.5 models. Most anime models are based on [[Stable Diffusion 1.5|Stable Diffusion 1.5]] and [[Novel AI or NAI|Novel AI]]. You should be able to check the version here:
</p>
![](https://lh4.googleusercontent.com/gFysITnyxkBIVRI1_6kBrpA3o366aMmfSSxHDBqcohYkfIBQIviy780R-logt7_yuq3XzKArmTNZLzOYouz_a_XDcHE2y9MYiSHSI3j34fx5Xs7GlGhuvP8RVuudsyw44xIPG8sObHwM_e0p-K8kBGY)


Next: [[1.1 Samplers]] 