Here, dumping details is actually pretty ok to make a picture appear more natural (as long as not every detail is important). For example, most bedrooms have a form of light in there, but anime generated pictures do not necessarily have them. Adding "lamp, lights, lights on, windows," relatively late into the prompt can help the model add details to make it seem realistic.
If you are stumped for details, you can ask ChatGPT, or look up pictures on the internet, then name what you see then throw it into CLIP or DeepBooru in the img2img tab. Alternatively, you can just leave it up to the model, but it's kinda random what you get. I actually know a lot less about this; if someone has extensive experience with background / landscape prompting, I'm very interested to hear your thoughts. 

Here's a list of basic backgrounds and some objects they might have (do start with e.g. background, forest):

\[colour\] background, simple background, 

<font color=F1ACAB>City street / city background:</font>
\[insert name of city\], crowd, \[adjective\] streets, traffic lights, pylon, skyscraper, trains, cars, trucks, bridge, trees, 

<font color=F1ACAB>Living room:</font>
fireplace, couch, lamp, wood, chair, table, book shelves, rug, windows, door window, potted plants, ornament shelves, plate shelves, XX era,

<font color=F1ACAB>Forest:</font>
trees, bamboo, grass, hills, valley, spring, summer, autumn, winter, snow, ice, rain, dew, river, stream, lake, pond, wildlife, \[animal\], 

Some more sceneries: cave, cyberpunk, machinery, abstract, bedroom, office, fantasy,

There's still a section on this in the <a href="INSERTLINKHERE">Intermediate Guide</a>, part of the "fighting against bias" section. 

Next: [[4. Camera + View]]
